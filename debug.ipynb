{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 257, 1280])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "ip_adapter_image_embeds = [torch.randn(1,257,1280),torch.randn(1,1,512)]\n",
    "repeat_dims = [1]\n",
    "image_embeds = []\n",
    "num_images_per_prompt = 1\n",
    "for single_image_embeds in ip_adapter_image_embeds:\n",
    "    single_image_embeds = single_image_embeds.repeat(\n",
    "        num_images_per_prompt, *(repeat_dims * len(single_image_embeds.shape[1:]))\n",
    "    )\n",
    "    image_embeds.append(single_image_embeds)\n",
    "image_embeds[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 512])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeds[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "ip_adapter_image_embeds = torch.randn(2, 3, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A man img wears eyeglasses and hat. This man has beard.\n"
     ]
    }
   ],
   "source": [
    "MATCHED_WORDS = [\"person\", \"male\", \"female\", \"man\", \"woman\", \"men\", \"women\"]\n",
    "\n",
    "def insert_img_after_keyword(text):\n",
    "    for word in MATCHED_WORDS:\n",
    "        index = text.find(word)\n",
    "        if index != -1:\n",
    "            # Find the end index of the matched word\n",
    "            end_index = index + len(word)\n",
    "            # Insert \"img\" after the matched word\n",
    "            new_text = text[:end_index] + \" img\" + text[end_index:]\n",
    "            return new_text\n",
    "    return text\n",
    "\n",
    "# Example usage\n",
    "input_text = \"A man wears eyeglasses and hat. This man has beard.\"\n",
    "output_text = insert_img_after_keyword(input_text)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "start_idx = 0\n",
    "video_length = 16  \n",
    "required_frame_num = 16*8\n",
    "frame_stride=8\n",
    "frame_indices = np.linspace(start_idx, start_idx + required_frame_num - 1, num=video_length, dtype=int)\n",
    "frame_indices = [start_idx + frame_stride*i for i in range(video_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设我们有两个形状相同的张量\n",
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4])\n",
    "\n",
    "# 使用torch.cat进行拼接\n",
    "cat_result = torch.cat((a, b), dim=0)  # 结果: tensor([1, 2, 3, 4])\n",
    "\n",
    "# 使用torch.stack进行堆叠\n",
    "stack_result = torch.stack((a, b))     # 结果: tensor([[1, 2],\n",
    "cat_result.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
